{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1/50, Loss: 1.5651051998138428\n",
      "Epoch 2/50, Loss: 1.2320154905319214\n",
      "Epoch 3/50, Loss: 0.9101012349128723\n",
      "Epoch 4/50, Loss: 0.9171878099441528\n",
      "Epoch 5/50, Loss: 0.7801293134689331\n",
      "Epoch 6/50, Loss: 0.7476625442504883\n",
      "Epoch 7/50, Loss: 0.4924246668815613\n",
      "Epoch 8/50, Loss: 0.6151297688484192\n",
      "Epoch 9/50, Loss: 0.40008893609046936\n",
      "Epoch 10/50, Loss: 0.557799220085144\n",
      "Epoch 11/50, Loss: 0.4816283583641052\n",
      "Epoch 12/50, Loss: 0.5058638453483582\n",
      "Epoch 13/50, Loss: 0.3502313494682312\n",
      "Epoch 14/50, Loss: 0.47574883699417114\n",
      "Epoch 15/50, Loss: 0.4167807996273041\n",
      "Epoch 16/50, Loss: 0.4260186553001404\n",
      "Epoch 17/50, Loss: 0.2502123713493347\n",
      "Epoch 18/50, Loss: 0.46812501549720764\n",
      "Epoch 19/50, Loss: 0.6329783201217651\n",
      "Epoch 20/50, Loss: 0.5013670325279236\n",
      "Epoch 21/50, Loss: 0.5192995071411133\n",
      "Epoch 22/50, Loss: 0.33697426319122314\n",
      "Epoch 23/50, Loss: 0.3697982728481293\n",
      "Epoch 24/50, Loss: 0.20690429210662842\n",
      "Epoch 25/50, Loss: 0.4063797891139984\n",
      "Epoch 26/50, Loss: 0.6052739024162292\n",
      "Epoch 27/50, Loss: 0.3820880055427551\n",
      "Epoch 28/50, Loss: 0.5387670993804932\n",
      "Epoch 29/50, Loss: 0.65241938829422\n",
      "Epoch 30/50, Loss: 0.19393134117126465\n",
      "Epoch 31/50, Loss: 0.3483593761920929\n",
      "Epoch 32/50, Loss: 0.5316837430000305\n",
      "Epoch 33/50, Loss: 0.36983615159988403\n",
      "Epoch 34/50, Loss: 0.36507880687713623\n",
      "Epoch 35/50, Loss: 0.4326398968696594\n",
      "Epoch 36/50, Loss: 0.30619198083877563\n",
      "Epoch 37/50, Loss: 0.2703915536403656\n",
      "Epoch 38/50, Loss: 0.3596084713935852\n",
      "Epoch 39/50, Loss: 0.5474428534507751\n",
      "Epoch 40/50, Loss: 0.4237041473388672\n",
      "Epoch 41/50, Loss: 0.38424602150917053\n",
      "Epoch 42/50, Loss: 0.3603309392929077\n",
      "Epoch 43/50, Loss: 0.3136679530143738\n",
      "Epoch 44/50, Loss: 0.4437134265899658\n",
      "Epoch 45/50, Loss: 0.24182429909706116\n",
      "Epoch 46/50, Loss: 0.35784637928009033\n",
      "Epoch 47/50, Loss: 0.25220993161201477\n",
      "Epoch 48/50, Loss: 0.394493043422699\n",
      "Epoch 49/50, Loss: 0.29935604333877563\n",
      "Epoch 50/50, Loss: 0.15230537950992584\n",
      "Test Accuracy: 83.62%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define ResNet-18 architecture\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = torch.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "# Hyperparameters\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "batch_size = 128\n",
    "learning_rate = 0.1\n",
    "epochs = 50\n",
    "\n",
    "# Data loading and preprocessing\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Model, loss function, and optimizer\n",
    "net = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "net = net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# Training\n",
    "for epoch in range(epochs):\n",
    "    net.train()\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print training loss after each epoch\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "# Testing\n",
    "net.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
